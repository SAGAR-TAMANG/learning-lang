{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.60-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 (from langgraph)\n",
      "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.48-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.3,>=0.1.125 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading langsmith-0.2.6-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading orjson-3.10.12-cp311-none-win_amd64.whl.metadata (42 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests<3,>=2 (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langgraph-0.2.60-py3-none-any.whl (135 kB)\n",
      "Downloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
      "Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl (37 kB)\n",
      "Downloading langgraph_sdk-0.1.48-py3-none-any.whl (43 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.2.6-py3-none-any.whl (325 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl (74 kB)\n",
      "Downloading orjson-3.10.12-cp311-none-win_amd64.whl (135 kB)\n",
      "Using cached pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, orjson, msgpack, jsonpointer, idna, h11, charset-normalizer, certifi, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.7.0 certifi-2024.12.14 charset-normalizer-3.4.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.28 langgraph-0.2.60 langgraph-checkpoint-2.0.9 langgraph-sdk-0.1.48 langsmith-0.2.6 msgpack-1.1.0 orjson-3.10.12 pydantic-2.10.4 pydantic-core-2.27.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 urllib3-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct_1(text):\n",
    "  return text + \" hey\"\n",
    "\n",
    "def funct_2(text):\n",
    "  return text + \" hey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x25bb127ce50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"node_1\", funct_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x25bb127ce50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"node_2\", funct_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x25bb127ce50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"node_1\", \"node_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x25bb127ce50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"node_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.graph.Graph at 0x25bb127ce50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_finish_point(\"node_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World hey hey'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'node_1' is\n",
      "---\n",
      "hey hey\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'node_2' is\n",
      "---\n",
      "hey hey hey\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = 'hey'\n",
    "\n",
    "for output in app.stream(input):\n",
    "  for key, value in output.items():\n",
    "    print(f\"Output from node '{key}' is\")\n",
    "    print(\"---\")\n",
    "    print(value)\n",
    "  print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain) (0.3.28)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain) (0.2.6)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n",
      "  Using cached openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Using cached tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.7.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached jiter-0.8.2-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain_openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain_openai) (0.4.6)\n",
      "Downloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Downloading langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Using cached openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 13.0 MB/s eta 0:00:00\n",
      "Using cached tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Using cached jiter-0.8.2-cp311-cp311-win_amd64.whl (206 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Installing collected packages: tqdm, regex, propcache, numpy, multidict, jiter, greenlet, frozenlist, distro, attrs, aiohappyeyeballs, yarl, tiktoken, SQLAlchemy, aiosignal, openai, aiohttp, langchain-text-splitters, langchain_openai, langchain\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 attrs-24.3.0 distro-1.9.0 frozenlist-1.5.0 greenlet-3.1.1 jiter-0.8.2 langchain-0.3.13 langchain-text-splitters-0.3.4 langchain_openai-0.2.14 multidict-6.1.0 numpy-1.26.4 openai-1.58.1 propcache-0.2.1 regex-2024.11.6 tiktoken-0.8.0 tqdm-4.67.1 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\tamang\\documents\\github\\learning-lang--\\.venv\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "su_Du59mVed3pQmplQWo9IaU3RYHI0rr0mwCLSM3HHjIcGT51knVIwkk89eUHYp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv(\"SUTRA_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "su_Du59mVed3pQmplQWo9IaU3RYHI0rr0mwCLSM3HHjIcGT51knVIwkk89eUHYp\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(os.getenv(\"SUTRA_API_KEY\"))\n",
    "\n",
    "# Set the model as ChatGPT\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"SUTRA_API_KEY\"),\n",
    "    model=\"sutra-light\",\n",
    "    base_url=\"https://api.two.ai/v2\",\n",
    "    streaming=True  # Enable streaming\n",
    ")\n",
    "full_response = \"\"\n",
    "# Use the model to stream the response\n",
    "for chunk in model.stream(\"Hello there!\"):\n",
    "    if chunk.content:  # Check if 'content' field is not empty\n",
    "        full_response += chunk.content\n",
    "\n",
    "print(full_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "  # Use the model to stream the response\n",
    "  full_response = \"\"\n",
    "  for chunk in model.stream(input_1):\n",
    "      if chunk.content:  # Check if 'content' field is not empty\n",
    "          full_response += chunk.content\n",
    "\n",
    "  return full_response\n",
    "\n",
    "def function_2(input_2):\n",
    "  return \"Agent says: \" + input_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agent says: Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"node_2\", function_2)\n",
    "\n",
    "workflow.add_edge(\"agent\", \"node_2\")\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "app = workflow.compile()\n",
    "app.invoke(\"Hey what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from Node 'agent': \n",
      "---\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "---\n",
      "\n",
      "Output from Node 'node_2': \n",
      "---\n",
      "Agent says: Hello! How can I assist you today?\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"Hello there!\"\n",
    "\n",
    "for output in app.stream(input):\n",
    "  for key, value in output.items():\n",
    "    print(f\"Output from Node '{key}': \")\n",
    "    print(\"---\")\n",
    "    print(value)\n",
    "  print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Temperature Agent App\n",
    "\n",
    "### Step 1: Parse City from User Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "  complete_query = \"Your task is to only extract the city name from the given user input, and the user input is as follows: \" + input_1\n",
    "  \n",
    "  # Use the model to stream the response\n",
    "  full_response = \"\"\n",
    "  for chunk in model.stream(complete_query):\n",
    "      if chunk.content:  # Check if 'content' field is not empty\n",
    "          full_response += chunk.content\n",
    "\n",
    "  return full_response\n",
    "\n",
    "def function_2(input_2):\n",
    "  return \"Agent says: \" + input_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agent says: New York'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"node_2\", function_2)\n",
    "workflow.add_edge(\"agent\", \"node_2\")\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "app = workflow.compile()\n",
    "app.invoke(\"what's the temps like in New York today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Integrate OpeanWeather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "  complete_query = \"Your task is to only extract the city name from the given user input, and the user input is as follows: \" + input_1\n",
    "  \n",
    "  # Use the model to stream the response\n",
    "  full_response = \"\"\n",
    "  for chunk in model.stream(complete_query):\n",
    "      if chunk.content:  # Check if 'content' field is not empty\n",
    "          full_response += chunk.content\n",
    "\n",
    "  return full_response\n",
    "\n",
    "def function_2(input_2):\n",
    "  import requests\n",
    "\n",
    "  content = requests.get(f\"https://api.waqi.info/feed/{city}/?token=c0fefc7d9d85f48a966bce34493fa3739f17da95\")\n",
    "\n",
    "  return content.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from Node 'agent: \n",
      "---\n",
      "New York\n",
      "---\n",
      "Output from Node 'tool: \n",
      "---\n",
      "{'status': 'ok', 'data': {'aqi': 67, 'idx': 3309, 'attributions': [{'url': 'http://www.dec.ny.gov/', 'name': 'New York State Department of Environmental Conservation (NYSDEC)', 'logo': 'US-NYDEC.png'}, {'url': 'http://www.airnow.gov/', 'name': 'Air Now - US EPA'}, {'url': 'https://waqi.info/', 'name': 'World Air Quality Index Project'}], 'city': {'geo': [40.7127837, -74.0059413], 'name': 'New York', 'url': 'https://aqicn.org/city/newyork', 'location': ''}, 'dominentpol': 'pm25', 'iaqi': {'h': {'v': 79}, 'p': {'v': 1031.2}, 'pm25': {'v': 67}, 't': {'v': -1.1}, 'w': {'v': 1}}, 'time': {'s': '2024-12-27 00:00:00', 'tz': '-05:00', 'v': 1735257600, 'iso': '2024-12-27T00:00:00-05:00'}, 'forecast': {'daily': {'o3': [{'avg': 1, 'day': '2024-12-25', 'max': 7, 'min': 1}, {'avg': 2, 'day': '2024-12-26', 'max': 6, 'min': 1}, {'avg': 1, 'day': '2024-12-27', 'max': 3, 'min': 1}, {'avg': 4, 'day': '2024-12-28', 'max': 9, 'min': 1}, {'avg': 16, 'day': '2024-12-29', 'max': 19, 'min': 10}, {'avg': 6, 'day': '2024-12-30', 'max': 19, 'min': 2}, {'avg': 2, 'day': '2024-12-31', 'max': 5, 'min': 1}], 'pm10': [{'avg': 38, 'day': '2024-12-25', 'max': 54, 'min': 22}, {'avg': 56, 'day': '2024-12-26', 'max': 80, 'min': 20}, {'avg': 113, 'day': '2024-12-27', 'max': 183, 'min': 48}, {'avg': 62, 'day': '2024-12-28', 'max': 182, 'min': 15}, {'avg': 10, 'day': '2024-12-29', 'max': 13, 'min': 5}, {'avg': 9, 'day': '2024-12-30', 'max': 12, 'min': 3}, {'avg': 48, 'day': '2024-12-31', 'max': 76, 'min': 10}], 'pm25': [{'avg': 90, 'day': '2024-12-25', 'max': 123, 'min': 64}, {'avg': 127, 'day': '2024-12-26', 'max': 169, 'min': 59}, {'avg': 210, 'day': '2024-12-27', 'max': 311, 'min': 115}, {'avg': 132, 'day': '2024-12-28', 'max': 311, 'min': 46}, {'avg': 22, 'day': '2024-12-29', 'max': 30, 'min': 15}, {'avg': 26, 'day': '2024-12-30', 'max': 34, 'min': 9}, {'avg': 113, 'day': '2024-12-31', 'max': 165, 'min': 27}], 'uvi': [{'avg': 1, 'day': '2024-12-26', 'max': 2, 'min': 0}, {'avg': 0, 'day': '2024-12-27', 'max': 2, 'min': 0}, {'avg': 0, 'day': '2024-12-28', 'max': 1, 'min': 0}, {'avg': 0, 'day': '2024-12-29', 'max': 0, 'min': 0}, {'avg': 0, 'day': '2024-12-30', 'max': 1, 'min': 0}, {'avg': 0, 'day': '2024-12-31', 'max': 0, 'min': 0}]}}, 'debug': {'sync': '2024-12-27T15:07:33+09:00'}}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "workflow.add_edge(\"agent\", \"tool\")\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"tool\")\n",
    "\n",
    "app = workflow.compile()\n",
    "# app.invoke(\"what's the temps like in New York today?\")\n",
    "\n",
    "for output in app.stream(\"what's the temps like in New York today?\"):\n",
    "  for key, value in output.items():\n",
    "    print(f\"Output from Node '{key}: \")\n",
    "    print(\"---\")\n",
    "    print(value)\n",
    "  print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Applying AgentState (to maintain history) and applying Function 3 \n",
    "> function_3 in summary utilizes the outputs of agent and tool (i.e., function_1 and function_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentStudio = {}\n",
    "\n",
    "AgentStudio[\"messages\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state):\n",
    "  messages = state[\"messages\"]\n",
    "  user_input = messages[-1]\n",
    "  \n",
    "  # Use the model to stream the response\n",
    "  full_response = \"\"\n",
    "  for chunk in model.stream(\"Your task is to only extract the city name from the given user input, and the user input is as follows: \" + user_input):\n",
    "      if chunk.content:  # Check if 'content' field is not empty\n",
    "          full_response += chunk.content\n",
    "\n",
    "  state[\"messages\"].append(full_response)\n",
    "  return state\n",
    "\n",
    "def function_2(state):\n",
    "  messages = state[\"messages\"]\n",
    "  agent_response = messages[-1]\n",
    "  content = requests.get(f\"https://api.waqi.info/feed/{city}/?token=c0fefc7d9d85f48a966bce34493fa3739f17da95\")\n",
    "  \n",
    "  state[\"messages\"].append(content.json())\n",
    "  return state\n",
    "\n",
    "def function_3(state):\n",
    "  messages = state[\"messages\"]\n",
    "  user_input = messages[0]\n",
    "  available_info = str(messages[-1])\n",
    "\n",
    "  # Use the model to stream the response\n",
    "  full_response = \"\"\n",
    "  for chunk in model.stream(f\"Your task is to provide the concise information based on the question of the user and the available information. The user's query is: \" + user_input + \" \\n And the available info is: \" + available_info):\n",
    "      if chunk.content:  # Check if 'content' field is not empty\n",
    "          full_response += chunk.content\n",
    "  \n",
    "  state[\"messages\"].append(full_response)\n",
    "  return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "workflow.add_node(\"responder\", function_3)\n",
    "\n",
    "workflow.add_edge(\"agent\", \"tool\")\n",
    "workflow.add_edge(\"tool\", \"responder\")\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"responder\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from Node 'agent'\n",
      "---\n",
      "{'messages': ['What is the AQI like in New York today?', 'New York']}\n",
      "---\n",
      "Output from Node 'tool'\n",
      "---\n",
      "{'messages': ['What is the AQI like in New York today?', 'New York', {'status': 'ok', 'data': {'aqi': 66, 'idx': 3309, 'attributions': [{'url': 'http://www.dec.ny.gov/', 'name': 'New York State Department of Environmental Conservation (NYSDEC)', 'logo': 'US-NYDEC.png'}, {'url': 'http://www.airnow.gov/', 'name': 'Air Now - US EPA'}, {'url': 'https://waqi.info/', 'name': 'World Air Quality Index Project'}], 'city': {'geo': [40.7127837, -74.0059413], 'name': 'New York', 'url': 'https://aqicn.org/city/newyork', 'location': ''}, 'dominentpol': 'pm25', 'iaqi': {'h': {'v': 79.5}, 'p': {'v': 1031.3}, 'pm25': {'v': 66}, 't': {'v': -1.1}, 'w': {'v': 0.4}}, 'time': {'s': '2024-12-27 01:00:00', 'tz': '-05:00', 'v': 1735261200, 'iso': '2024-12-27T01:00:00-05:00'}, 'forecast': {'daily': {'o3': [{'avg': 1, 'day': '2024-12-25', 'max': 7, 'min': 1}, {'avg': 2, 'day': '2024-12-26', 'max': 6, 'min': 1}, {'avg': 1, 'day': '2024-12-27', 'max': 3, 'min': 1}, {'avg': 4, 'day': '2024-12-28', 'max': 9, 'min': 1}, {'avg': 16, 'day': '2024-12-29', 'max': 19, 'min': 10}, {'avg': 6, 'day': '2024-12-30', 'max': 19, 'min': 2}, {'avg': 2, 'day': '2024-12-31', 'max': 5, 'min': 1}], 'pm10': [{'avg': 38, 'day': '2024-12-25', 'max': 54, 'min': 22}, {'avg': 56, 'day': '2024-12-26', 'max': 80, 'min': 20}, {'avg': 113, 'day': '2024-12-27', 'max': 183, 'min': 48}, {'avg': 62, 'day': '2024-12-28', 'max': 182, 'min': 15}, {'avg': 10, 'day': '2024-12-29', 'max': 13, 'min': 5}, {'avg': 9, 'day': '2024-12-30', 'max': 12, 'min': 3}, {'avg': 48, 'day': '2024-12-31', 'max': 76, 'min': 10}], 'pm25': [{'avg': 90, 'day': '2024-12-25', 'max': 123, 'min': 64}, {'avg': 127, 'day': '2024-12-26', 'max': 169, 'min': 59}, {'avg': 210, 'day': '2024-12-27', 'max': 311, 'min': 115}, {'avg': 132, 'day': '2024-12-28', 'max': 311, 'min': 46}, {'avg': 22, 'day': '2024-12-29', 'max': 30, 'min': 15}, {'avg': 26, 'day': '2024-12-30', 'max': 34, 'min': 9}, {'avg': 113, 'day': '2024-12-31', 'max': 165, 'min': 27}], 'uvi': [{'avg': 1, 'day': '2024-12-26', 'max': 2, 'min': 0}, {'avg': 0, 'day': '2024-12-27', 'max': 2, 'min': 0}, {'avg': 0, 'day': '2024-12-28', 'max': 1, 'min': 0}, {'avg': 0, 'day': '2024-12-29', 'max': 0, 'min': 0}, {'avg': 0, 'day': '2024-12-30', 'max': 1, 'min': 0}, {'avg': 0, 'day': '2024-12-31', 'max': 0, 'min': 0}]}}, 'debug': {'sync': '2024-12-27T15:59:20+09:00'}}}]}\n",
      "---\n",
      "Output from Node 'responder'\n",
      "---\n",
      "The Air Quality Index (AQI) in New York today is 66, which falls into the \"Moderate\" category. The dominant pollutant is PM2.5. For more details, you can visit the [New York State Department of Environmental Conservation](http://www.dec.ny.gov/) or the [Air Now - US EPA](http://www.airnow.gov/).\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for output in app.stream({\"messages\": [\"What is the AQI like in New York today?\"]}):\n",
    "  for key, value in output.items():\n",
    "    print(f\"Output from Node '{key}'\")\n",
    "    print(\"---\")\n",
    "    print(value)\n",
    "  print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
